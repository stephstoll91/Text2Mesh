data:
    src: "text"    # Source - Either Gloss->Pose or Text->Pose (gloss,text)
    trg: "skels2d"    # Target - 3D body co-ordinates (skels)
    files: "files"    # Filenames for each sequence

    train: "/absolute/path/to/Text2Mesh/demo/TextData/train"
    dev: "/absolute/path/to/Text2Mesh/Text2Mesh/demo/TextData/dev"
    test: "/absolute/path/to/Text2Mesh/Text2Mesh/demo/TextData/test"

    max_sent_length: 400 # Max Sentence Length
    skip_frames: 1   # Skip frames in the data, to reduce the data input size

training:
    random_seed: 27   # Random seed for initialisation
    optimizer: "adam"   # Chosen optimiser (adam, ..)
    learning_rate: 0.001   # Initial model learning rate
    learning_rate_min: 0.0002 # Learning rate minimum, when training will stop
    weight_decay: 0.0   # Weight Decay
    clip_grad_norm: 5.0   # Gradient clipping value
    batch_size: 8    # Batch Size for training
    scheduling: "plateau"   # Scheduling at training time (plateau, ...)
    patience: 10  # How many epochs of no improvement causes a LR reduction
    decrease_factor: 0.9  # LR reduction factor, after the # of patience epochs
    early_stopping_metric: "bleu" # Which metric determines scheduling (DTW, loss, BT, roi)
    epochs: 20000  # How many epochs to run for
    validation_freq: 2000  # After how many steps to run a validation on the model
    logging_freq: 100  # After how many steps to log training progress
    eval_metric: "bleu"  # Evaluation metric during training (dtw', 'bt', 'roi')
    model_dir: "./model" # Where the model shall be stored
    overwrite: False # Flag to overwrite a previous saved model in the model_dir
    continue: True  # Flag to continue from a previous saved model in the model_dir
    shuffle: True  # Flag to shuffle the data during training
    use_cuda: True  # Flag to use GPU cuda capabilities
    max_output_length: 400 # Max Output Length
    keep_last_ckpts: 1 # How many previous best/latest checkpoints to keep
    loss: "MSE"  # Loss function (MSE, L1)
    loss_weights: [1.0, 1.0, 0.0001]


model:
    initializer: "xavier" # Model initialisation (Xavier, ...)
    bias_initializer: "zeros"  # Bias initialiser (Zeros, ...)
    embed_initializer: "xavier" # Embedding initialiser (Xavier, ...)
    trg_size: 100  # Size of target skeleton coordinates (150 for Inverse Kinematics body/hands)
    just_count_in: False # Flag for Just Counter Data Augmentation
    gaussian_noise: True # Flag for Gaussian Noise Data Augmentation
    noise_rate: 5 # Gaussian Noise rate
    future_prediction: 0 # Future Prediction Data Augmentation if > 0
    encoder:  # Model Encoder
        type: "transformer"
        num_layers: 2 # Number of layers
        num_heads: 8  # Number of Heads
        embeddings:
            embedding_dim: 256  # Embedding Dimension
            dropout: 0.0 # Embedding Dropout
        hidden_size: 256 # Hidden Size Dimension
        ff_size: 1024 # Feed-forward dimension (4 x hidden_size)
        dropout: 0.0 # Encoder Dropout
    decoder: # Model Decoder
        type: "transformer"
        num_layers: 2 # Number of layers
        num_heads: 8 # Number of Heads
        embeddings:
            embedding_dim: 256 # Embedding Dimension
            dropout: 0.0 # Embedding Dropout
        hidden_size: 256 # Hidden Size Dimension
        ff_size: 1024 # Feed-forward dimension (4 x hidden_size)
        dropout: 0.0 # Decoder Dropout

face_model:
    initializer: "xavier" # Model initialisation (Xavier, ...)
    bias_initializer: "zeros"  # Bias initialiser (Zeros, ...)
    embed_initializer: "xavier" # Embedding initialiser (Xavier, ...)
    trg_size: 140  # Size of target skeleton coordinates (150 for Inverse Kinematics body/hands)
    just_count_in: False # Flag for Just Counter Data Augmentation
    gaussian_noise: True # Flag for Gaussian Noise Data Augmentation
    noise_rate: 5 # Gaussian Noise rate
    future_prediction: 0 # Future Prediction Data Augmentation if > 0
    encoder:  # Model Encoder
        type: "transformer"
        num_layers: 2 # Number of layers
        num_heads: 8  # Number of Heads
        embeddings:
            embedding_dim: 256  # Embedding Dimension
            dropout: 0.0 # Embedding Dropout
        hidden_size: 256 # Hidden Size Dimension
        ff_size: 1024 # Feed-forward dimension (4 x hidden_size)
        dropout: 0.0 # Encoder Dropout
    decoder: # Model Decoder
        type: "transformer"
        num_layers: 2 # Number of layers
        num_heads: 8 # Number of Heads
        embeddings:
            embedding_dim: 256 # Embedding Dimension
            dropout: 0.0 # Embedding Dropout
        hidden_size: 256 # Hidden Size Dimension
        ff_size: 1024 # Feed-forward dimension (4 x hidden_size)
        dropout: 0.0 # Decoder Dropout

backtrans:
    name: sign_experiment
    data:
        data_path: /path/to/Text2Mesh/demo/TextData/
        version: phoenix_2014_trans
        sgn: sign
        txt: text
        gls: gloss
        train: train.
        dev: dev.
        test: test.
        feature_size: 100
        level: word
        txt_lowercase: true
        max_sent_length: 400
        random_train_subset: -1
        random_dev_subset: -1
        gls_vocab: gls.vocab
        txt_vocab: txt.vocab
    testing:
        recognition_beam_sizes:
            - 10
        translation_beam_sizes:
            - 1
        translation_beam_alphas:
            - -1
    training:
        reset_best_ckpt: false
        reset_scheduler: false
        reset_optimizer: false
        random_seed: 42
        model_dir: "/path/to/Text2Mesh/demo/eval_model/sign_sample_model_200_r0t1_all_256_1024_2D_pose_hands"
        recognition_loss_weight: 0.0
        translation_loss_weight: 1.0
        eval_metric: bleu
        optimizer: adam
        learning_rate: 0.001
        batch_size: 32
        num_valid_log: 5
        epochs: 5000000
        early_stopping_metric: eval_metric
        batch_type: sentence
        translation_normalization: batch
        eval_recognition_beam_size: 1
        eval_translation_beam_size: 1
        eval_translation_beam_alpha: -1
        overwrite: true
        shuffle: true
        use_cuda: true
        translation_max_output_length: 30
        keep_last_ckpts: 1
        batch_multiplier: 1
        logging_freq: 100
        validation_freq: 100
        betas:
            - 0.9
            - 0.998
        scheduling: plateau
        learning_rate_min: 1.0e-07
        weight_decay: 0.001
        patience: 10
        decrease_factor: 0.9
        label_smoothing: 0.0
    model:
        initializer: xavier
        bias_initializer: zeros
        init_gain: 1.0
        embed_initializer: xavier
        embed_init_gain: 1.0
        tied_softmax: false
        encoder:
            type: transformer
            num_layers: 3
            num_heads: 8
            embeddings:
                embedding_dim: 256
                scale: false
                dropout: 0.1
                norm_type: batch
                activation_type: softsign
            hidden_size: 256
            ff_size: 1024
            dropout: 0.1
        decoder:
            type: transformer
            num_layers: 3
            num_heads: 8
            embeddings:
                embedding_dim: 256
                scale: false
                dropout: 0.1
                norm_type: batch
                activation_type: softsign
            hidden_size: 256
            ff_size: 1024
            dropout: 0.1

